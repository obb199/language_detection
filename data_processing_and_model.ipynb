{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PlSZ2_3OaePY",
        "outputId": "71a2a7da-359e-4284-a0fd-9b25fe83fc5e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "w2Fhjh7LaTnY"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "from IPython import display\n",
        "import os\n",
        "import cv2\n",
        "import gc\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#bloco de código para criar os arquivos de áudio com 10 segundos que serão usados\n",
        "\n",
        "portuguese = '/content/drive/MyDrive/audios/português'\n",
        "english = '/content/drive/MyDrive/audios/inglês'\n",
        "\n",
        "dirs_portuguese = os.listdir(portuguese)\n",
        "dirs_english = os.listdir(english)[0:len(dirs_portuguese)]\n",
        "\n",
        "k = []\n",
        "counter = -1\n",
        "for p, e in zip(dirs_portuguese, dirs_english):\n",
        "  for init in range(10, 240, 8):\n",
        "    counter += 1\n",
        "    try:\n",
        "      y, sr = librosa.load(portuguese + '/' + p, offset=init, duration=10.0)\n",
        "      sf.write(f'/content/drive/MyDrive/audios/inputs/portuguese_inputs/{counter}.wav', y, sr)\n",
        "    except:\n",
        "      k.append(portuguese + '/' + p)\n",
        "\n",
        "    try:\n",
        "      y, sr = librosa.load(english + '/' + e, offset=init, duration=10.0)\n",
        "      sf.write(f'/content/drive/MyDrive/audios/inputs/english_inputs/{counter}.wav', y, sr)\n",
        "    except:\n",
        "      k.append(english + '/' + e)\n"
      ],
      "metadata": {
        "id": "LvGuGtLiCikf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_waveform(file_path):\n",
        "  audio_binary = tf.io.read_file(file_path)\n",
        "  waveform, _ = tf.audio.decode_wav(contents=audio_binary)\n",
        "  waveform = tf.reshape(waveform, (220500))\n",
        "  return waveform\n",
        "\n",
        "def show_waveform(waveform):\n",
        "  plt.plot(waveform)"
      ],
      "metadata": {
        "id": "vZmDfZiLfZpM"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_spectrogram(waveform):\n",
        "  # Zero-padding for an audio waveform with less than 16,000 samples.\n",
        "  input_len = 220500\n",
        "  waveform = waveform[:input_len]\n",
        "  zero_padding = tf.zeros(\n",
        "      [220500] - tf.shape(waveform),\n",
        "      dtype=tf.float32)\n",
        "  # Cast the waveform tensors' dtype to float32.\n",
        "  waveform = tf.cast(waveform, dtype=tf.float32)\n",
        "  # Concatenate the waveform with `zero_padding`, which ensures all audio\n",
        "  # clips are of the same length.\n",
        "  equal_length = tf.concat([waveform, zero_padding], 0)\n",
        "  # Convert the waveform to a spectrogram via a STFT.\n",
        "  spectrogram = tf.signal.stft(\n",
        "      equal_length, frame_length=2048, frame_step=128)\n",
        "  # Obtain the magnitude of the STFT.\n",
        "  spectrogram = tf.abs(spectrogram)\n",
        "  # Add a `channels` dimension, so that the spectrogram can be used\n",
        "  # as image-like input data with convolution layers (which expect\n",
        "  # shape (`batch_size`, `height`, `width`, `channels`).\n",
        "  spectrogram = spectrogram[..., tf.newaxis]\n",
        "  return spectrogram"
      ],
      "metadata": {
        "id": "B8z2w3ywshzi"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_spectrogram_for_model(directory):\n",
        "  wave_array = get_waveform(directory)\n",
        "  spectrogram_of_wave = np.array(get_spectrogram(wave_array))\n",
        "  normalized_spectrogram = (spectrogram_of_wave - spectrogram_of_wave.min())/(spectrogram_of_wave.max() - spectrogram_of_wave.min())\n",
        "\n",
        "  return normalized_spectrogram\n"
      ],
      "metadata": {
        "id": "ztibtNoOL6Mg"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = create_spectrogram_for_model('/content/drive/MyDrive/audios/inputs/english_inputs/1.wav')"
      ],
      "metadata": {
        "id": "k4tvjoStXsJ9"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MK-D5SehAb_o",
        "outputId": "2af2d3a0-e9c6-45c6-923c-c6696c5f3cdf"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1707, 1025, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#bloco de código para ler os arquivos de 3s e processá-los\n",
        "x = []\n",
        "y = []\n",
        "\n",
        "portuguese_audios = os.listdir('/content/drive/MyDrive/audios/inputs/portuguese_inputs')\n",
        "english_audios = os.listdir('/content/drive/MyDrive/audios/inputs/english_inputs')\n",
        "\n",
        "for idx in range(1, min(len(portuguese_audios), len(english_audios))):\n",
        "  try:\n",
        "    spectrogram = create_spectrogram_for_model('/content/drive/MyDrive/audios/inputs/portuguese_inputs/' + str(idx) + '.wav')\n",
        "    x.append(cv2.resize(spectrogram[:800,:800, 0], (500, 250)))\n",
        "    y.append(1)\n",
        "  except:\n",
        "    pass\n",
        "\n",
        "  try:\n",
        "    spectrogram = create_spectrogram_for_model('/content/drive/MyDrive/audios/inputs/english_inputs/' + str(idx) + '.wav')\n",
        "    x.append(cv2.resize(spectrogram[:800,:800, 0], (500, 250)))\n",
        "    y.append(0)\n",
        "  except:\n",
        "    pass\n",
        "\n",
        "x = np.array(x)\n",
        "y = np.array(y)\n",
        "\n",
        "print(x.shape)\n",
        "print(y.shape)"
      ],
      "metadata": {
        "id": "uHHLz-TjUHlc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90e94ca3-576d-4da9-8565-d1bb86de2e11"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1965, 250, 500)\n",
            "(1965,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def division_dataset(X, y, train_ratio=0.5, val_ratio=0.23, test_ratio=0.27):\n",
        "  \"\"\"\n",
        "  função para dividir o dataset completo em treino, validação e teste.\n",
        "  \"\"\"\n",
        "  if train_ratio + test_ratio + val_ratio != 1: ##criar um raise aqui\n",
        "    return False\n",
        "\n",
        "  len_dataset = X.shape[0]\n",
        "  train_x, train_y, val_x, val_y, test_x, test_y = [], [], [], [], [], []\n",
        "\n",
        "  random.seed(2023)\n",
        "\n",
        "  for i in range(X.shape[0]):\n",
        "    r = random.random()\n",
        "    if r <= train_ratio:\n",
        "      train_x.append(X[i])\n",
        "      train_y.append(y[i])\n",
        "    elif r <= train_ratio + val_ratio:\n",
        "      val_x.append(X[i])\n",
        "      val_y.append(y[i])\n",
        "    else:\n",
        "      test_x.append(X[i])\n",
        "      test_y.append(y[i])\n",
        "    \n",
        "  return np.array(train_x, dtype='float16'), np.array(train_y, dtype='float16'), np.array(val_x, dtype='float16'), np.array(val_y, dtype='float16'), np.array(test_x, dtype='float16'), np.array(test_y, dtype='float16')"
      ],
      "metadata": {
        "id": "2UWB1EEiXPWr"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_x, train_y, val_x, val_y, test_x, test_y = division_dataset(x, y)"
      ],
      "metadata": {
        "id": "7CDKFmdphXAD"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_x.shape, train_y.shape, val_x.shape, val_y.shape, test_x.shape, test_y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yejFp70MggOQ",
        "outputId": "ed83608a-dc7e-46ca-a5e9-e1d3d8530e59"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((965, 250, 500), (965,), (457, 250, 500), (457,), (543, 250, 500), (543,))"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential()\n",
        "\n",
        "model.add(tf.keras.layers.Conv2D(input_shape=(250, 500, 1), filters=32, kernel_size=(3,3), use_bias=True, padding='same', activation='relu'))\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3), use_bias=True, padding='same', activation='relu'))\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "model.add(tf.keras.layers.MaxPool2D(pool_size=(3,3)))\n",
        "model.add(tf.keras.layers.Conv2D(filters=128, kernel_size=(3,3), use_bias=True, padding='same', activation='relu'))\n",
        "model.add(tf.keras.layers.MaxPool2D(pool_size=(3,3)))\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.Dense(units=1024, activation=('selu'), kernel_initializer='lecun_normal'))\n",
        "model.add(tf.keras.layers.Dense(1, activation=('sigmoid')))\n",
        "\n",
        "model.compile(optimizer='adam', \n",
        "              loss='binary_crossentropy', \n",
        "              metrics=[tf.keras.metrics.CategoricalAccuracy(), \n",
        "                       tf.keras.metrics.Precision(),\n",
        "                       tf.keras.metrics.AUC()])"
      ],
      "metadata": {
        "id": "IEl1sbCEW8g8"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "F7vrb2fcZd9y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9334e709-e085-4ddc-89b3-4c29d04e6406"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_18 (Conv2D)          (None, 250, 500, 32)      320       \n",
            "                                                                 \n",
            " batch_normalization_18 (Bat  (None, 250, 500, 32)     128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_19 (Conv2D)          (None, 250, 500, 64)      18496     \n",
            "                                                                 \n",
            " batch_normalization_19 (Bat  (None, 250, 500, 64)     256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_7 (MaxPooling  (None, 83, 166, 64)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_20 (Conv2D)          (None, 83, 166, 128)      73856     \n",
            "                                                                 \n",
            " max_pooling2d_8 (MaxPooling  (None, 27, 55, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " batch_normalization_20 (Bat  (None, 27, 55, 128)      512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " flatten_5 (Flatten)         (None, 190080)            0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 1024)              194642944 \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 1)                 1025      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 194,737,537\n",
            "Trainable params: 194,737,089\n",
            "Non-trainable params: 448\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_x, train_y,\n",
        "            batch_size=16,\n",
        "            epochs=10,\n",
        "            validation_data=(val_x, val_y),\n",
        "            shuffle=True)"
      ],
      "metadata": {
        "id": "TtMfBPCMcW-B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8766376-33a3-4b1d-8fe1-c18de727e99c"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "61/61 [==============================] - 18s 257ms/step - loss: 8.7081 - categorical_accuracy: 1.0000 - precision_3: 0.6057 - auc_3: 0.6156 - val_loss: 22.5581 - val_categorical_accuracy: 1.0000 - val_precision_3: 0.0000e+00 - val_auc_3: 0.5000\n",
            "Epoch 2/10\n",
            "61/61 [==============================] - 15s 245ms/step - loss: 0.6813 - categorical_accuracy: 1.0000 - precision_3: 0.7470 - auc_3: 0.8312 - val_loss: 14.6012 - val_categorical_accuracy: 1.0000 - val_precision_3: 0.0000e+00 - val_auc_3: 0.5000\n",
            "Epoch 3/10\n",
            "61/61 [==============================] - 15s 245ms/step - loss: 0.4472 - categorical_accuracy: 1.0000 - precision_3: 0.8025 - auc_3: 0.8765 - val_loss: 15.2245 - val_categorical_accuracy: 1.0000 - val_precision_3: 0.0000e+00 - val_auc_3: 0.5000\n",
            "Epoch 4/10\n",
            "61/61 [==============================] - 15s 244ms/step - loss: 0.3556 - categorical_accuracy: 1.0000 - precision_3: 0.8559 - auc_3: 0.9231 - val_loss: 13.5507 - val_categorical_accuracy: 1.0000 - val_precision_3: 0.0000e+00 - val_auc_3: 0.5000\n",
            "Epoch 5/10\n",
            "61/61 [==============================] - 15s 242ms/step - loss: 0.2424 - categorical_accuracy: 1.0000 - precision_3: 0.9048 - auc_3: 0.9667 - val_loss: 7.9018 - val_categorical_accuracy: 1.0000 - val_precision_3: 0.0000e+00 - val_auc_3: 0.5000\n",
            "Epoch 6/10\n",
            "61/61 [==============================] - 15s 242ms/step - loss: 0.1480 - categorical_accuracy: 1.0000 - precision_3: 0.9411 - auc_3: 0.9887 - val_loss: 2.9663 - val_categorical_accuracy: 1.0000 - val_precision_3: 0.0000e+00 - val_auc_3: 0.5944\n",
            "Epoch 7/10\n",
            "61/61 [==============================] - 15s 243ms/step - loss: 0.0888 - categorical_accuracy: 1.0000 - precision_3: 0.9753 - auc_3: 0.9958 - val_loss: 2.9557 - val_categorical_accuracy: 1.0000 - val_precision_3: 0.0000e+00 - val_auc_3: 0.5964\n",
            "Epoch 8/10\n",
            "61/61 [==============================] - 15s 244ms/step - loss: 0.0600 - categorical_accuracy: 1.0000 - precision_3: 0.9876 - auc_3: 0.9975 - val_loss: 1.0593 - val_categorical_accuracy: 1.0000 - val_precision_3: 0.6259 - val_auc_3: 0.6036\n",
            "Epoch 9/10\n",
            "61/61 [==============================] - 15s 243ms/step - loss: 0.0320 - categorical_accuracy: 1.0000 - precision_3: 0.9979 - auc_3: 0.9987 - val_loss: 1.3911 - val_categorical_accuracy: 1.0000 - val_precision_3: 0.5064 - val_auc_3: 0.6320\n",
            "Epoch 10/10\n",
            "61/61 [==============================] - 15s 244ms/step - loss: 0.0200 - categorical_accuracy: 1.0000 - precision_3: 0.9979 - auc_3: 0.9985 - val_loss: 2.7835 - val_categorical_accuracy: 1.0000 - val_precision_3: 0.4933 - val_auc_3: 0.5297\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f49a32e62b0>"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(test_x, test_y, batch_size=1)"
      ],
      "metadata": {
        "id": "jQxo916o9zcU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34fda638-cff7-424c-838d-49103ecb228d"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "543/543 [==============================] - 6s 10ms/step - loss: 2.5264 - categorical_accuracy: 1.0000 - precision_2: 0.0000e+00 - auc_2: 0.6095\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.5263874530792236, 1.0, 0.0, 0.6095101833343506]"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#full english test\n",
        "k = []\n",
        "english_x = []\n",
        "english_y = []\n",
        "counter = 0\n",
        "for init in range(10, 230, 10):\n",
        "    counter += 1\n",
        "    y, sr = librosa.load('/content/drive/MyDrive/audios/inglês/WOJAK ASKS HIS WIFE FOR MONEY TO INVEST IN THE CRYPTO MARKET.3gpp', offset=init, duration=10.0)\n",
        "    sf.write(f'file{counter}.wav', y, sr)\n",
        "\n",
        "for i in range(1, counter):\n",
        "    spectrogram = create_spectrogram_for_model(f'file{i}.wav')\n",
        "    english_x.append(cv2.resize(spectrogram, (500, 250)))\n",
        "    english_y.append(0)\n"
      ],
      "metadata": {
        "id": "OfKScvw6WnuQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#full test portuguese\n",
        "k = []\n",
        "portuguese_x = []\n",
        "portuguese_y = []\n",
        "counter = 0\n",
        "for init in range(10, 230, 10):\n",
        "    counter += 1\n",
        "    y, sr = librosa.load('/content/drive/MyDrive/audios/português/Quanto Tempo de Fato um Programador Fica Codificando  Formação DEV cortes.3gpp', offset=init, duration=10.0)\n",
        "    sf.write(f'pfile{counter}.wav', y, sr)\n",
        "\n",
        "for i in range(1, counter):\n",
        "  try:\n",
        "    spectrogram = create_spectrogram_for_model(f'pfile{i}.wav')\n",
        "    portuguese_x.append(cv2.resize(spectrogram, (500, 250)))\n",
        "    portuguese_y.append(1)\n",
        "  except:\n",
        "    pass"
      ],
      "metadata": {
        "id": "Nh841T1VPjN4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "english_x, english_y = np.array(english_x), np.array(english_y)\n",
        "portuguese_x, portuguese_y = np.array(portuguese_x), np.array(portuguese_y)"
      ],
      "metadata": {
        "id": "ALSBMjoPPB84"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(english_x, english_y, batch_size=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SyAC4SXJQMtr",
        "outputId": "d23f404d-970c-427a-cdfd-a9dbf1aae7a3"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "21/21 [==============================] - 1s 13ms/step - loss: 0.0061 - categorical_accuracy: 1.0000 - precision_2: 0.0000e+00 - auc_2: 0.0000e+00\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.006144034676253796, 1.0, 0.0, 0.0]"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(portuguese_x, portuguese_y, batch_size=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-8xbX_b5QT5A",
        "outputId": "b1486a19-1c58-4199-dab9-d64c039b1bf2"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "21/21 [==============================] - 0s 13ms/step - loss: 5.3727 - categorical_accuracy: 1.0000 - precision_2: 0.0000e+00 - auc_2: 0.0000e+00\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[5.372665882110596, 1.0, 0.0, 0.0]"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    }
  ]
}
